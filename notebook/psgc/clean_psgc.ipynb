{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Philippine Standard Geographic Code Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the PSGC Excel file.\n",
    "\n",
    "The Philippine Statistics Authority publishes an updated PSGC file every quarter in the form of an Excel file. The latest link is here: https://psa.gov.ph/classification/psgc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc_excel = pd.read_excel(\"../../dataset/psgc/raw/PSGC_Publication_Sept2018.xlsx\",sheet_name=\"PSGC\")\n",
    "psgc_excel.to_csv('../../dataset/psgc/raw/raw-psgc.csv.gz',encoding=\"utf-8\",compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43797 entries, 0 to 43796\n",
      "Data columns (total 9 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   Unnamed: 0                         43797 non-null  int64 \n",
      " 1   Code                               43797 non-null  int64 \n",
      " 2   Name                               43797 non-null  object\n",
      " 3   Inter-Level                        43795 non-null  object\n",
      " 4   City Class                         145 non-null    object\n",
      " 5   Income\n",
      "Classification              1715 non-null   object\n",
      " 6   Urban / Rural (based on 2010 CPH)  42047 non-null  object\n",
      " 7   POPULATION\n",
      "(2015 POPCEN)           43795 non-null  object\n",
      " 8   Unnamed: 7                         8 non-null      object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "psgc = pd.read_csv('../../dataset/psgc/raw/raw-psgc.csv.gz',encoding=\"utf-8\")\n",
    "psgc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert \"Code\" column to a string and ensure it has leading zeros and is 9-char long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc.loc[:,\"Code\"] = psgc.Code.astype(str).str.zfill(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unused columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc = psgc.loc[:,['Code','Name','Inter-Level']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc.columns = ['code','location','interlevel']\n",
    "psgc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc['interlevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a duplicate of the original PSGC dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_psgc = psgc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that a lot of the locations in the PSGC have alternate names or aliases for each location contained in parentheses. Let's create a regular expression pattern that will extract these as aliases and append these as additional rows to each subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_in_paren = re.compile(r'\\(+([^\\(\\)]+)\\)*')\n",
    "remove_in_paren = \"\\(.+\\)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_in_paren(df):\n",
    "    \n",
    "    '''\n",
    "    Denotes original locations\n",
    "    '''\n",
    "    df['original'] = True\n",
    "    \n",
    "    '''\n",
    "    Creates a copy of the rows that contain parentheses or have aliases.\n",
    "    '''\n",
    "    has_paren = df[df.location.str.contains(\"[\\(\\)]\")]\n",
    "    has_paren['original'] = False\n",
    "    \n",
    "    '''\n",
    "    Splits locations that contain parentheses into two elements -- what's before the parentheses, and what's within them\n",
    "    Each of these items is treated as a separate possible alias and appended to the original datasete\n",
    "    '''\n",
    "    for i in [0,1]:\n",
    "        aliases = has_paren.copy()\n",
    "        aliases['location'] = has_paren.location.str.replace(\"\\)\",\"\").str.split(\"\\(\").str.get(i).str.strip()\n",
    "        df = df.append(aliases,ignore_index=True)\n",
    "        \n",
    "    \n",
    "    return df.sort_values(by=[\"code\",\"original\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = psgc[psgc['interlevel'] == 'Reg'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternate names inside parens so we expand those out to a new column named `alias`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = expand_in_paren(regions)\n",
    "regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean provinces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = psgc[psgc['interlevel'] == 'Prov'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems normal... But let's check for parens just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces[provinces['location'].str.contains('[\\(\\)]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sneaky alternate names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = expand_in_paren(provinces)\n",
    "provinces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = psgc[psgc['interlevel'] == 'Dist'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No one writes `NTH DISTRICT (Not a Province)` in their addresses. Let's remove these instances altogether rather than extract these as aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts['location'] = (districts['location']\n",
    "                         .str.replace('\\(Not a Province\\)', '')\n",
    "                         .str.strip()\n",
    "                         .str.split(',',n=1)\n",
    "                         .str.get(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities = psgc[psgc['interlevel'] == 'Mun'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for alternate names in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities[municipalities['location'].str.contains('[\\(\\)]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases the words \"Capital\" are contained in parentheses but these are not aliases. Safe to strip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities['location'] = municipalities['location'].str.replace('\\(Capital\\)', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipalities = expand_in_paren(municipalities)\n",
    "municipalities.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = psgc[psgc['interlevel'] == 'City'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go with the `(Capital)` thing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['location'] =  cities['location'].str.replace('\\(Capital\\)', '').str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if there are still stuff with parens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities['location'].str.contains('[\\(\\)]')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few alterate names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = expand_in_paren(cities)\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what about those `CITY` pre/suffixes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[cities['location'].str.contains('CITY')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's strip any prefixes of \"CITY OF\" and suffixes of \"CITY.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities['location'] = (cities['location']\n",
    " .str.replace('^.*CITY OF', '') #stripping prefixes\n",
    " .str.strip()\n",
    " .str.replace('CITY$', '') #stripping suffixes\n",
    " .str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean sub-municipalities\n",
    "\n",
    "Manila is the only city-slash-district that has submunicipalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_municipalities = psgc[psgc['interlevel'] == 'SubMun'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_municipalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing special!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean barangays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays = psgc[psgc['interlevel'] == 'Bgy'].copy()\n",
    "barangays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see alternate names again but notice the `(Pob.)` suffixes. A quick Google search shows that it's short for `Poblacion` which is used to denote the commercial and industrial center of a city. Let's just strip these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays['location'] = (barangays['location']\n",
    "                         .str.replace('(\\(Pob\\.\\))', '') #totally do away with any poblacion suffixes\n",
    "                         .str.strip())\n",
    "barangays['location'].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many other barangay names contain parentheses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays[barangays.location.str.contains(r'[\\(\\)]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While parentheses often contain aliases, sometimes, these are not aliases but the name of the municipality in which the barangay is located. For example, barangays in the municipality of Dumalneg have the `(Dumalneg)` denoted in parentheses. We'll go ahead and extract parenthetical names as aliases for now, but we'll later remove instances in which aliases are equal to the municipality name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays = expand_in_paren(barangays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for more weird characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays[barangays['location'].str.contains(r'[^a-zA-Z0-9\\sÑñ\\(\\)]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets extract the strings that follow a \"Brgy No. X\" as aliases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_barangay = re.compile('(B[gr]y. No. \\d+\\-?\\w?),? (.+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(barangays[barangays.location.str.contains(pat_barangay)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_barangays(df):\n",
    "    \n",
    "    '''\n",
    "    Denotes original locations\n",
    "    '''\n",
    "    df['original'] = True\n",
    "    \n",
    "    '''\n",
    "    Creates a copy of the rows that contain barangay pattern\n",
    "    '''\n",
    "    matches_pattern = df[df.location.str.contains(pat_barangay)]\n",
    "    matches_pattern['original'] = False\n",
    "    \n",
    "    '''\n",
    "    Splits locations that into two elements -- Brgy No X and the name that comes after it\n",
    "    Each of these items is treated as a separate possible alias and appended to the original datasete\n",
    "    '''\n",
    "    for i in [0,1]:\n",
    "        aliases = matches_pattern.copy()\n",
    "        aliases['location'] = matches_pattern.location.str.extract(pat_barangay)[i]#.str.get(i).str.strip()\n",
    "        aliases['location'] = aliases['location'].str.strip()\n",
    "        df = df.append(aliases,ignore_index=True)\n",
    "        \n",
    "    return df.sort_values(by=[\"code\",\"original\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print len(barangays)\n",
    "barangays = expand_barangays(barangays)\n",
    "#print len(barangays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangays[barangays.code == \"012812026\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMM: Cotabato and Isabela City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armm = psgc[psgc['interlevel'].isnull()].copy()\n",
    "armm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armm['location'] = armm['location'].str.replace('\\(Not a Province\\)', '')\n",
    "armm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armm['location'] = (armm['location']\n",
    " .str.replace('^.*CITY OF', '')\n",
    " .str.strip()\n",
    " .str.replace('CITY$', '')\n",
    " .str.strip())\n",
    "armm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "armm['original'] = True\n",
    "armm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([\n",
    "    regions,\n",
    "    provinces,\n",
    "    districts,\n",
    "    municipalities,\n",
    "    cities,\n",
    "    sub_municipalities,\n",
    "    barangays,\n",
    "    armm\n",
    "],ignore_index=True).sort_index().fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are counts still correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psgc['interlevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['interlevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.code.nunique(), psgc.code.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = merged[merged['location'].str.contains(' (UNO|DOS|TRES|KUATRO|SINGKO)$',case=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate([\n",
    "    'Uno',\n",
    "    'Dos',\n",
    "    'Tres',\n",
    "    'Kuatro',\n",
    "    'Singko',\n",
    "]):\n",
    "    spanish['location'] = spanish['location'].str.replace(' {}$'.format(s), ' {}'.format(i + 1))\n",
    "spanish\n",
    "spanish['original'] = False\n",
    "spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman = merged[merged['location'].str.contains('\\s(X{0,3})(IX|IV|V?I{0,3})$')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, s in enumerate('I,II,III,IV,V,VI,VII,VIII,IX,X,XI,XII,XIII,XIV,XV,XVI,XVII,XVIII,XIX,XX,XXI,XXII'.split(',')):\n",
    "    roman['location'] = roman['location'].str.replace(' {}$'.format(s), ' {}'.format(i + 1))\n",
    "roman['original'] = False\n",
    "roman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide alternate names for locations with President names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "president = merged[merged.location.str.contains('PRES\\.', flags=re.IGNORECASE)].copy()\n",
    "president['location'] = president['location'].str.replace('^PRES\\.', 'PRESIDENT')\n",
    "president['location'] = president['location'].str.replace('^Pres\\.', 'President')\n",
    "president['original'] = False\n",
    "president"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add alternative names to Metro Manila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metro_manila = pd.DataFrame([{\"code\":\"130000000\",\"interlevel\":\"Reg\",\"location\":\"Metro Manila\",\"original\":False},\n",
    "              {\"code\":\"130000000\",\"interlevel\":\"Reg\",\"location\":\"Metropolitan Manila\",\"original\":False}])\n",
    "\n",
    "metro_manila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Ñ -> N as an alternate name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[merged.location.str.contains('Las Piñas',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enye = merged[merged.location.str.contains(r'[Ññ]')].copy()\n",
    "enye.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enye['location'] = (enye['location'].str.replace('Ñ', 'N')\n",
    "                    .str.replace('ñ','n'))\n",
    "enye.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat the alternates to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc = (pd.concat([merged, spanish, roman, president], ignore_index=True)\n",
    "              .sort_values('code')\n",
    "              .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last check for weird stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc[clean_psgc['location'].str.contains('[^a-zA-Z0-9 \\-.,\\']')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can probably still split with `&` and `/` but this is good enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the cleaned up PSGC and remove the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc.drop_duplicates(subset=['code', 'location', 'interlevel'], inplace=True)\n",
    "clean_psgc.reset_index(drop=True).sort_values('code', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we have both the original name and the alternate ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc[clean_psgc.code.str.contains('086000000')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc[clean_psgc.code.str.contains('012801001')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning out rows in which the alternate name of the barangay was just the name of its parent municipality or city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc['municipality_code'] = clean_psgc.code.str.slice(0,6)+\"000\"\n",
    "clean_psgc['municipality'] = clean_psgc['municipality_code'].map(municipalities[municipalities.original==True].set_index('code').location)\n",
    "clean_psgc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc['drop'] = (clean_psgc.municipality == clean_psgc.location.str.upper()) & (clean_psgc.interlevel == \"Bgy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barangay_and_muni_same_name = clean_psgc.groupby('code').drop.value_counts().unstack()[False][clean_psgc.groupby('code').drop.value_counts().unstack()[False].isnull()].index\n",
    "clean_psgc.loc[clean_psgc.code.isin(barangay_and_muni_same_name),\"drop\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc = clean_psgc.loc[clean_psgc['drop'] ==False,['code','interlevel','location','original']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc[clean_psgc.code == \"133900000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create aliases for Legazpi and Ozamiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zplaces = clean_psgc[clean_psgc.location.str.upper().isin([\"LEGAZPI\",\"OZAMIZ\"])].copy()\n",
    "zplaces.loc[:,'location'] = [\"LEGASPI\",\"OZAMIS\"]\n",
    "zplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_psgc = clean_psgc.append(zplaces,ignore_index=True)\n",
    "clean_psgc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_psgc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e9cad410fa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_psgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../dataset/psgc/processed/clean-psgc.csv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clean_psgc' is not defined"
     ]
    }
   ],
   "source": [
    "clean_psgc.to_csv('../../dataset/psgc/processed/clean-psgc.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "318px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
